{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Ensure notebook is being run from base repository directory\n",
    "import os, sys\n",
    "try:\n",
    "#     os.chdir(\"/home/{}/forecast_rodeo_ii\".format(os.environ[\"USER\"]))\n",
    "    os.chdir(\"/Users/quetzal/Documents/code/covid/covid19-forecast-hub\")\n",
    "except Exception as err:\n",
    "    print(f\"Warning: unable to change directory; {repr(err)}\")\n",
    "from src.utils.notebook_util import isnotebook\n",
    "if isnotebook():\n",
    "    # Autoreload packages that are modified\n",
    "    %load_ext autoreload\n",
    "    %autoreload 2\n",
    "else:\n",
    "    from argparse import ArgumentParser\n",
    "    \n",
    "# Computational libraries \n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.metrics import mean_squared_error\n",
    "import numpy.matlib\n",
    "from collections import deque\n",
    "\n",
    "# os libraries \n",
    "import shutil\n",
    "from datetime import datetime, timedelta\n",
    "from functools import partial\n",
    "import copy\n",
    "import pdb\n",
    "import os\n",
    "\n",
    "from utils import *\n",
    "from file_util import *\n",
    "from attributes import *\n",
    "\n",
    "from zoo_of_experts import *\n",
    "from zoo_of_hinters import *\n",
    "from zoo_of_losses import *\n",
    "\n",
    "\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#\n",
    "# Specify model parameters\n",
    "#\n",
    "model_name = \"online_expert\" \n",
    "\n",
    "if not isnotebook():\n",
    "    # If notebook run as a script, parse command-line arguments\n",
    "    parser = ArgumentParser()\n",
    "    parser.add_argument(\"pos_vars\",nargs=\"*\")  # gt_id and horizon \n",
    "    \n",
    "    parser.add_argument('--target_dates', '-t', default=\"std_future\")\n",
    "    parser.add_argument('--expert_models', '-m', default=\"doy,cfsv2,multillr,llr\",\n",
    "                       help='Comma separated list of models e.g., <doy,cfsv2,llr,multillr>')\n",
    "    parser.add_argument('--reg', '-r', default=\"entropic\",\n",
    "                       help='Regularization type, one of: <quadratic>, <entropic> <orig>, <opt_delay>, <plusplus>')\n",
    "    parser.add_argument('--alg', '-a', default=\"adahedgefo\",\n",
    "                       help='Online learning algorithm. One of: <ftl>, <ftrl>, <adahedgefo>, <adahedgesr>, <flip_flop>, <rm>, <rmplus>.')\n",
    "    parser.add_argument('--quarters', '-q', default=\"False\",\n",
    "                       help='Whether to reset learning at each quarter. If False, learning is run over all target dates.')    \n",
    "    parser.add_argument('--hint', '-hi', default=\"None\",\n",
    "                       help='Optimistic hints, only used with adahedgefo. One of: <None>, <doy>, <prev_y>, <trend_y>, <prev_z>, <mean_z>.')  \n",
    "    parser.add_argument('--delay', '-d', default=0,\n",
    "                       help='Delay parameter, number of experts to instantiate. String containting an integer >=0.')      \n",
    "    parser.add_argument('--exp_name', '-e', default=\"None\",\n",
    "                       help='Experiment name prefix, use \"None\" if not running an experiment to use standard submodel name.')\n",
    "    args, opt = parser.parse_known_args()\n",
    "    \n",
    "    # Assign variables                                                                                                                                     \n",
    "    gt_id = get_id_name(args.pos_vars[0]) # \"contest_precip\" or \"contest_tmp2m\"                                                                            \n",
    "    horizon = get_th_name(args.pos_vars[1]) # \"34w\" or \"56w\"    \n",
    "    target_date_str = args.target_dates # target date object\n",
    "    model_string = args.expert_models # string of expert prediction, comma separated\n",
    "    reg = args.reg # algorithm regularization \n",
    "    alg = args.alg # algorithm \n",
    "    reset_quarters = args.quarters # reset quarters \n",
    "    hint_type = args.hint # type of optimistic hint\n",
    "    exp_name = args.exp_name # name of experiment, to be prepended to submodel name\n",
    "    delay_param = int(args.delay) # delay parameter \n",
    "else:\n",
    "    # Otherwise, specify arguments interactively\n",
    "    gt_id = \"cumm_death\" #\"contest_precip\", \"contest_tmp2m\"    \n",
    "    target_date_str = \"std_weekly\" #\"contest_precip\", \"contest_tmp2m\"\n",
    "    location = 'US'\n",
    "    quantile = 0.5\n",
    "    horizon = \"1w\"\n",
    "    alg = 'rmplus' # 'ftl', ftrl', 'adahedgefo', 'adahedgesr', 'flip_flop', 'rm', 'rmplus'\n",
    "    hint_type = \"mean_g\"\n",
    "    delay_param = 0\n",
    "    exp_name = \"None\" # Set experiment name, use \"None\" if not running an experiment\n",
    "    reg = \"None\" # 'quadratic', 'entropic'\n",
    "    \n",
    "'''\n",
    "Adaptive hinting parameters\n",
    "'''\n",
    "hint_alg = 'rmplus' # 'ftl', ftrl', 'adahedgefo', 'adahedgesr', 'flip_flop', 'rm', 'rmplus'\n",
    "hint_reg = \"None\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "Read in ground truth and model predictions for task\n",
    "\"\"\"\n",
    "# Get location FIPS codes\n",
    "fips_codes = get_fips_codes() \n",
    "\n",
    "# Read ground truth \n",
    "printf(f'Loading {gt_id} ground truth')\n",
    "gt = get_ground_truth(gt_id, location, load_df=True)\n",
    "\n",
    "# Get target dates\n",
    "first_date, last_date = get_data_range(gt_id, location=location)\n",
    "printf(f\"Getting target dates from {first_date} to {last_date}.\")\n",
    "target_dates = get_target_dates(target_date_str, first_date, last_date)\n",
    "target_date_objs = pd.Series(target_dates)\n",
    "\n",
    "# Store delta between target date and forecast issuance date\n",
    "start_delta = timedelta(days=get_start_delta(horizon, gt_id))\n",
    "\n",
    "# Get model predicitons for the task\n",
    "printf(f'Loading model predictions for {gt_id}, {horizon}, {location}, q{quantile}')\n",
    "model_pred_df = get_model_predictions(gt_id, horizon, location=location, quantile=quantile, load_df=True)\n",
    "\n",
    "# Get model list\n",
    "persistant_models, all_models = get_persistant_models(model_pred_df)\n",
    "expert_models = list(all_models)\n",
    "expert_models.sort()\n",
    "model_string = (',').join(expert_models)\n",
    "printf(f\"Predictions for models loaded:\\n {expert_models}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "Visualize ground truth \n",
    "\"\"\"\n",
    "df_gt.plot()\n",
    "plt.xticks(rotation=90)\n",
    "plt.title(f'Ground truth {gt_id}')\n",
    "plt.show()\n",
    "\n",
    "\"\"\"\n",
    "Visualize avalible models\n",
    "\"\"\"\n",
    "plt.plot(list(persistant_models.keys()), [len(x) for x in persistant_models.values()])\n",
    "plt.xticks(rotation=90)\n",
    "plt.title('Persistant models avaliable by date')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "display(gt)\n",
    "display(model_pred_df)\n",
    "len(expert_models)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "Set up online learning parameterization\n",
    "\"\"\"\n",
    "# Record submodel name for the online expert model\n",
    "submodel_name = get_submodel_name(\n",
    "    expert_models=model_string, \n",
    "    reg=reg, \n",
    "    alg=alg, \n",
    "    quarters=reset_quarters,\n",
    "    hint = hint_type,\n",
    "    delay=delay_param,\n",
    "    training_dates=target_date_str,\n",
    "    exp_name=exp_name)\n",
    "\n",
    "printf(f\"Submodel name {submodel_name}\")\n",
    "\n",
    "if not isnotebook():\n",
    "    # TODO: need to set this up\n",
    "    # Save output to log file\n",
    "    logger = start_logger(model=model_name,submodel=submodel_name,gt_id=gt_id,\n",
    "                          horizon=horizon,target_dates=target_date_str)\n",
    "    # Store parameter values in log                                                                                                                        \n",
    "    params_names = ['gt_id', 'horizon', 'target_date_str',\n",
    "                    'model_string', 'alg',\n",
    "                    'reg', 'reset_quarters', 'hint_type',\n",
    "                    'delay_param', 'exp_name']\n",
    "    params_values = [eval(param) for param in params_names]\n",
    "    log_params(params_names, params_values)  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "Instantiate loss\n",
    "'''\n",
    "rodeo_loss = MAELoss()\n",
    "hint_loss = HintingLossTwoNorm()\n",
    "\n",
    "''' \n",
    "Instantiate prototype online learner\n",
    "'''\n",
    "\n",
    "# Instantiate expert\n",
    "num_experts = delay_param + 1\n",
    "oe = get_expert(alg=alg, loss=rodeo_loss, T=duration//num_experts, \n",
    "                expert_list=expert_models, init_method=\"uniform\", reg=reg, \n",
    "                init_df=init_df)  \n",
    "printf(f\"-initializing online_expert for with duration {duration//num_experts}\")   \n",
    "\n",
    "'''\n",
    "Instantiate hint generator\n",
    "'''\n",
    "if alg == \"rm\" or alg == \"rmplus\":\n",
    "    regret_hints = True # Provide pseudo-regret hints\n",
    "else:\n",
    "    regret_hints = False # Provide cummulative gradient hints\n",
    "\n",
    "# TODO: delay horizon \n",
    "# In order, list of 1 day hints, 12w hints, 34w hint, future hints, etc.\n",
    "horizon_hints = [[\"prev_y\"], \n",
    "                 [hint_type],\n",
    "                 [hint_type],\n",
    "                 [hint_type]]    \n",
    "    \n",
    "n_hints = [sum(len(x) for x in horizon_hints)]\n",
    "hint_models = [item + str(i) for i, sublist in enumerate(horizon_hints) for item in sublist]\n",
    "hint_partition = [i for i, sublist in enumerate(horizon_hints) for item in sublist]\n",
    "\n",
    "# Initialize \n",
    "printf(f\"-initializing joint hinter of type {hint_models}\")   \n",
    "hinter = JointHinter(gt_id, horizon_hints, oe, regret_hints)\n",
    "\n",
    "'''\n",
    "Instantiate prototype online hinter\n",
    "'''\n",
    "oh = get_expert(alg=hint_alg, loss=hint_loss, T=duration//num_experts, \n",
    "                expert_list=hint_models, init_method=\"uniform\", reg=hint_reg,\n",
    "                partition=hint_partition) \n",
    "\n",
    "printf(f\"-initializing online_expert for with duration {duration//num_experts}\")  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Store rmses\n",
    "rmses = pd.Series(index=target_date_objs, dtype='float64')\n",
    "regret_gt = pd.DataFrame(columns=expert_models, index=target_date_objs, dtype='float64')\n",
    "regret_gt.fillna(0, inplace=True) # Fill with zeros\n",
    "online_params = None\n",
    "online_hint_params = None\n",
    "expert_pred_df = None\n",
    "hint_pred_df = None\n",
    "\n",
    "'''\n",
    "Initialize online experts\n",
    "'''\n",
    "ei = 0\n",
    "experts_dates = {}\n",
    "hinters_dates = {}\n",
    "experts_queue = [None]*(num_experts)\n",
    "hinters_queue = [None]*(num_experts)\n",
    "for e in range(num_experts):\n",
    "    experts_dates[e] = []    \n",
    "    hinters_dates[e] = []      \n",
    "    hinters_queue[e] = copy.deepcopy(oh)        \n",
    "    experts_queue[e] = copy.deepcopy(oe)    \n",
    "      \n",
    "'''\n",
    "Perform online prediction\n",
    "'''\n",
    "for target_date_obj in target_date_objs:\n",
    "    printf(f\"\\n\\n\\t----- Starting {target_date_obj}\") \n",
    "    \n",
    "    '''\n",
    "    Get each expert model prediction for the target date and merge into single dataframe.\n",
    "    Add predictions to the backlog in expert_df\n",
    "    '''\n",
    "    \n",
    "    tic()\n",
    "    # Convert target date to string\n",
    "    date_str = datetime.strftime(target_date_obj, '%Y-%m-%d')  \n",
    "         \n",
    "    # Get expert predictions for target date and skip target dates if not all experts have a forecast\n",
    "    merged_df, missing_experts = get_pred_by_date(model_pred_df, date_str, expert_models)    \n",
    "    toc()\n",
    "    \n",
    "    # TODO: need to deal with missing experts\n",
    "    # if len(missing_experts) > 0 or merged_df.shape[0] < 1:\n",
    "    #     printf(f\"warning: experts {missing_experts} unavailable for target={target_date_obj}; skipping\")\n",
    "    #     continue\n",
    "    tic()\n",
    "    \n",
    "    # Update full expert_df; keep past predictions around to perform updates of w and hints       \n",
    "    if expert_pred_df is None:\n",
    "        expert_pred_df = merged_df.copy()\n",
    "    else:\n",
    "        expert_pred_df = pd.merge(expert_pred_df, merged_df, \n",
    "                         left_index=True, right_index=True, how='outer', \n",
    "                         on=expert_models).sort_index()\n",
    "        \n",
    "    '''\n",
    "    Get an avalible expert to make a prediction for target dates. \n",
    "    '''\n",
    "    cur_oe = experts_queue[ei]\n",
    "    cur_oh = hinters_queue[ei] \n",
    "    \n",
    "    # Update parameter logging\n",
    "    params = cur_oe.log_params()\n",
    "    hint_params = cur_oh.log_params()            \n",
    "    \n",
    "    # Update parameter set for dates in target range\n",
    "    if online_params is None:                                                \n",
    "         online_params = pd.DataFrame(params, index=[target_date_obj])        \n",
    "    else:                                                                    \n",
    "        online_params.loc[target_date_obj] = copy.copy(params)\n",
    "        \n",
    "    if online_hint_params is None:                                                \n",
    "         online_hint_params = pd.DataFrame(hint_params, index=[target_date_obj])        \n",
    "    else:                                                                    \n",
    "        online_hint_params.loc[target_date_obj] = copy.copy(hint_params)          \n",
    "    '''\n",
    "    Update model weights with previously avaliable ground truth; use current \n",
    "    prediction to provide optimistic hint, if necessary.\n",
    "    '''\n",
    "    pred = None # Initialize prediction\n",
    "    printf(f\"Making target prediction {target_date_obj} using expert {ei} with experience {cur_oe.t}.\")  \n",
    "    \n",
    "    # Add current target date to outstanding predictions\n",
    "    experts_dates[ei].append(target_date_obj)\n",
    "\n",
    "    last_data_date = target_date_obj - start_delta\n",
    "    printf(f\"--Last data date {last_data_date}\")\n",
    "\n",
    "    pdb.set_trace()\n",
    "    printf(expert_pred_df)\n",
    "    # Get expert prediction dates that are avalible for updates\n",
    "    update_dates = [x for x in experts_dates[ei] if x <= last_data_date]\n",
    "    if len(update_dates) > 1:\n",
    "        raise ValueError(f\"Warning: more than one date in the update queue {len(update_dates)}\")\n",
    "        \n",
    "    for date in update_dates:\n",
    "        expert_pred = expert_pred_df.loc[(expert_pred_df.index.get_level_values('target_date') == date)]\n",
    "        hinter_pred = hint_pred_df.loc[(hint_pred_df.index.get_level_values('target_date') == date)]\n",
    "        \n",
    "        if gt.index.get_level_values(\"target_date\").isin([date]).any():   \n",
    "            printf(f\"Updating expert {ei} w/{cur_oe.t} experience with forecast on {target_date_obj}.\")\n",
    "            printf(f\"--Outstanding expert predictions: {len(experts_dates[ei])} for expert {ei}\")   \n",
    "            \n",
    "            d = experts_dates[ei].pop(0) # Remove prediction to be updated from outstanding predictions\n",
    "\n",
    "            # Check that that oustanding prediction is correct\n",
    "            if d != date: raise ValueError(f\"Bad date {d} != {date}\")\n",
    "                \n",
    "\n",
    "            ''' Get loss gradient '''       \n",
    "            grad = cur_oe.loss_gradient(\n",
    "                     X=expert_pred.to_numpy(copy=False), \n",
    "                     y=gt[date].to_numpy(copy=False),\n",
    "                     w=online_params.loc[date][expert_models].to_numpy(copy=False))\n",
    "\n",
    "            ''' Update regret ground truth '''\n",
    "            r = cur_oe.loss_regret(g=grad, w=online_params.loc[date][expert_models].to_numpy(copy=False))\n",
    "            regret_gt.loc[date, expert_models] = r\n",
    "               \n",
    "\n",
    "            ''' Get hint value '''  \n",
    "            hinter.update_hint_data(g_fb=grad, y_fb=gt[date].to_numpy(copy=False))  \n",
    "            \n",
    "            H = hinter.get_hint_matrix(\n",
    "                        X_all=expert_pred_df,\n",
    "                        y_all=gt,\n",
    "                        w_all=online_params[expert_models],\n",
    "                        last_data_date=last_data_date,\n",
    "                        os_preds=experts_dates[ei])\n",
    "\n",
    "            ''' Get hint weights '''\n",
    "            hint = cur_oh.update_and_predict(\n",
    "                         X_cur=H,\n",
    "                         X_fb=hint_pred_df.loc[date].to_numpy(copy=False).T, \n",
    "                         y_fb=regret_gt.loc[experts_dates[ei], :].to_numpy(copy=False).sum(axis=0),\n",
    "                         w_fb=online_hint_params.loc[date, hint_models].to_numpy(copy=False))\n",
    "            printf(f\"Hint: {hint}\")  \n",
    "            \n",
    "            ''' Get prediction for target date '''\n",
    "            pred = cur_oe.update_and_predict(\n",
    "                         X_cur=merged_df[expert_models].to_numpy(copy=False),\n",
    "                         hint=hint,\n",
    "                         X_fb=expert_pred.to_numpy(copy=False), \n",
    "                         y_fb=gt[date].to_numpy(copy=False),\n",
    "                         w_fb=online_params.loc[date][expert_models].to_numpy(copy=False))\n",
    "            print(\"pred shape:\", pred.shape)\n",
    "\n",
    "            # Remove updated date  \n",
    "            expert_pred_df.drop(date, level=0, inplace=True)    \n",
    "                \n",
    "    # If no data was avaliable for predict and update, make a prediction without feedback\n",
    "    if pred is None:\n",
    "        # Before the first feedback\n",
    "        H = hinter.get_hint_matrix(\n",
    "                        X_all=expert_pred_df,\n",
    "                        y_all=gt,\n",
    "                        w_all=online_params[expert_models],       \n",
    "                        last_data_date=last_data_date,\n",
    "                        os_preds=experts_dates[ei])\n",
    "        \n",
    "        hint = cur_oh.update_and_predict(X_cur=H)        \n",
    "        printf(f\"Hint grad sum: {hint}\")\n",
    "        '''\n",
    "        Get prediction for target date without feedback\n",
    "        '''\n",
    "        pred = cur_oe.update_and_predict(\n",
    "                     X_cur=merged_df[expert_models].to_numpy(copy=False),\n",
    "                     hint=hint\n",
    "        )\n",
    "        print(\"pred shape:\", pred.shape)\n",
    "    '''\n",
    "    Update hinting historical parameters\n",
    "    '''\n",
    "    index = pd.MultiIndex.from_arrays(\n",
    "        [[target_date_obj]*len(hint_models), hint_models], \n",
    "        names=('target_date', 'hint'))\n",
    "    \n",
    "    if hint_pred_df is None:\n",
    "        hint_pred_df = pd.DataFrame(H.T, columns=expert_models, index=index)        \n",
    "    else:\n",
    "        df = pd.DataFrame(H.T, columns=expert_models, index=index)                \n",
    "        hint_pred_df = pd.merge(hint_pred_df, df, on=expert_models,\n",
    "                         left_index=True, right_index=True, how='outer')\n",
    "        \n",
    "    '''\n",
    "    Mark the current expert as busy until delay_delta days before gt is avalible\n",
    "    '''\n",
    "    # Add expert with key providing the next target date for which the expert can make predictions\n",
    "    ei = (ei+1) % num_experts\n",
    "    '''\n",
    "    Save forecasts and update metric logging\n",
    "    '''\n",
    "    params = cur_oe.log_params()\n",
    "    hint_params = cur_oh.log_params()    \n",
    "    printf(f\"-alg params:\\n{params}\\n\")\n",
    "    printf(f\"-hint params:\\n{hint_params}\\n\")        \n",
    "\n",
    "    # Update parameter set for dates in target range\n",
    "    if online_params is None:                                                \n",
    "         online_params = pd.DataFrame(params, index=[target_date_obj])        \n",
    "    else:                                                                    \n",
    "        online_params.loc[target_date_obj] = params.values()\n",
    "    if online_hint_params is None:                                                \n",
    "         online_hint_params = pd.DataFrame(hint_params, index=[target_date_obj])        \n",
    "    else:                                                                    \n",
    "        online_hint_params.loc[target_date_obj] = hint_params.values()        \n",
    "        \n",
    "    # Store expert weights\n",
    "    merged_df['pred'] = pred\n",
    "    # Save prediction to file in standard format\n",
    "    save_forecasts(merged_df.reset_index()[[\"target_date\", \"lat\", \"lon\", \"pred\"]],\n",
    "        model=model_name, \n",
    "        submodel=submodel_name, \n",
    "        gt_id=gt_id, \n",
    "        horizon=horizon, \n",
    "        target_date_str=date_str)\n",
    "    \n",
    "    # Skip dates without forecast outputs\n",
    "    if not gt.index.get_level_values(0).isin([target_date_obj]).any():\n",
    "        printf(f\"warning: some features unavailable for target={target_date_obj}; skipping evalution.\")\n",
    "        printf(\"-mean rmse: {}, running score: {}\".format(mean_rmse, mean_rmse_to_score(mean_rmse)))        \n",
    "        printf(\"-rmse: {}, score: {}\".format(rmse, mean_rmse_to_score(rmse)))        \n",
    "    else: \n",
    "        # Evaluate and store error\n",
    "        rmse = cur_oe.loss(gt[target_date_obj].to_numpy(), pred)\n",
    "        rmses.loc[target_date_obj] = rmse\n",
    "        printf(\"-rmse: {}, score: {}\".format(rmse, mean_rmse_to_score(rmse)))\n",
    "        mean_rmse = rmses.mean()\n",
    "        printf(\"-mean rmse: {}, running score: {}\".format(mean_rmse, mean_rmse_to_score(mean_rmse)))\n",
    "        \n",
    "# Save rmses in standard format\n",
    "rmses = rmses.reset_index()\n",
    "rmses.columns = ['target_date','rmse']\n",
    "\n",
    "# Get output directory and create if it doesn't exist\n",
    "output_folder = get_task_metrics_dir(model=model_name, \n",
    "                                     submodel=submodel_name, \n",
    "                                     gt_id=gt_id, \n",
    "                                     horizon=horizon)\n",
    "make_directories(output_folder)\n",
    "metric_file_path = f'{output_folder}/rmse-{gt_id}_{horizon}-{target_date_str}.h5'\n",
    "pandas2hdf(rmses, metric_file_path)\n",
    "\n",
    "\n",
    "# Log online learning parameters to file\n",
    "logdir = get_task_forecast_dir(model=model_name, \n",
    "                               submodel=submodel_name,\n",
    "                               gt_id=gt_id, \n",
    "                               horizon=horizon)\n",
    "make_directories(logdir)\n",
    "param_file_path = f'{logdir}/learning_params-{gt_id}_{horizon}-{target_date_str}.h5'\n",
    "pandas2hdf(online_params, param_file_path)\n",
    "\n",
    "hint_param_file_path = f'{logdir}/hint_params-{gt_id}_{horizon}-{target_date_str}.h5'\n",
    "pandas2hdf(online_hint_params, hint_param_file_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
