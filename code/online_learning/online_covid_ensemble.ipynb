{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Ensure notebook is being run from base repository directory\n",
    "import os, sys\n",
    "try:\n",
    "#     os.chdir(\"/home/{}/forecast_rodeo_ii\".format(os.environ[\"USER\"]))\n",
    "    os.chdir(\"/Users/quetzal/content/covid-ensembles/covid19-forecast-hub\")\n",
    "except Exception as err:\n",
    "    print(f\"Warning: unable to change directory; {repr(err)}\")\n",
    "from src.utils.notebook_util import isnotebook\n",
    "if isnotebook():\n",
    "    # Autoreload packages that are modified\n",
    "    %load_ext autoreload\n",
    "    %autoreload 2\n",
    "else:\n",
    "    from argparse import ArgumentParser\n",
    "    \n",
    "# Computational libraries \n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.metrics import mean_squared_error\n",
    "import numpy.matlib\n",
    "from collections import deque\n",
    "\n",
    "# os libraries \n",
    "import shutil\n",
    "from datetime import datetime, timedelta\n",
    "from functools import partial\n",
    "import copy\n",
    "import pdb\n",
    "import os\n",
    "\n",
    "from utils import *\n",
    "from file_util import *\n",
    "from attributes import *\n",
    "\n",
    "from zoo_of_experts import *\n",
    "from zoo_of_hinters import *\n",
    "from zoo_of_losses import *\n",
    "\n",
    "\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#\n",
    "# Specify model parameters\n",
    "#\n",
    "model_name = \"online_expert\" \n",
    "\n",
    "if not isnotebook():\n",
    "    # If notebook run as a script, parse command-line arguments\n",
    "    parser = ArgumentParser()\n",
    "    parser.add_argument(\"pos_vars\",nargs=\"*\")  # gt_id and horizon \n",
    "    \n",
    "    parser.add_argument('--target_dates', '-t', default=\"std_future\")\n",
    "    parser.add_argument('--reg', '-r', default=\"entropic\",\n",
    "                       help='Regularization type, one of: <quadratic>, <entropic> <orig>, <opt_delay>, <plusplus>')\n",
    "    parser.add_argument('--alg', '-a', default=\"adahedgefo\",\n",
    "                       help='Online learning algorithm. One of: <ftl>, <ftrl>, <adahedgefo>, <adahedgesr>, <flip_flop>, <rm>, <rmplus>.')\n",
    "    parser.add_argument('--hint', '-hi', default=\"None\",\n",
    "                       help='Optimistic hints, only used with adahedgefo. One of: <None>, <doy>, <prev_y>, <trend_y>, <prev_z>, <mean_z>.')  \n",
    "    parser.add_argument('--delay', '-d', default=0,\n",
    "                       help='Delay parameter, number of experts to instantiate. String containting an integer >=0.')      \n",
    "    parser.add_argument('--exp_name', '-e', default=\"None\",\n",
    "                       help='Experiment name prefix, use \"None\" if not running an experiment to use standard submodel name.')\n",
    "    parser.add_argument('--location', '-l', default=\"US\",\n",
    "                       help='Experimental location, a two character state abbrevaition or \"US\".')  \n",
    "    parser.add_argument('--quantile', '-q', default=0.5,\n",
    "                       help='Prediction quantile. Default to 0.5 for median prediction\".')      \n",
    "    args, opt = parser.parse_known_args()\n",
    "    \n",
    "    # Assign variables                                                                                                                                     \n",
    "    gt_id = get_id_name(args.pos_vars[0]) # \"contest_precip\" or \"contest_tmp2m\"                                                                            \n",
    "    horizon = get_th_name(args.pos_vars[1]) # \"34w\" or \"56w\"    \n",
    "    target_date_str = args.target_dates # target date object\n",
    "    location = args.location # target date object\n",
    "    quantile = args.quantile\n",
    "    alg = args.alg # algorithm \n",
    "    reg = args.reg # algorithm regularization \n",
    "    hint_type = args.hint # type of optimistic hint\n",
    "    delay_param = int(args.delay) # delay parameter     \n",
    "    exp_name = args.exp_name # name of experiment, to be prepended to submodel name\n",
    "else:\n",
    "    # Otherwise, specify arguments interactively\n",
    "    gt_id = \"incd_case\" #\"contest_precip\", \"contest_tmp2m\"    \n",
    "    horizon = \"1w\"    \n",
    "    target_date_str = \"std_weekly\" #\"contest_precip\", \"contest_tmp2m\"\n",
    "    location = 'US'\n",
    "    quantile = 0.5\n",
    "    alg = 'rmplus' # 'ftl', ftrl', 'adahedgefo', 'adahedgesr', 'flip_flop', 'rm', 'rmplus'\n",
    "    reg = \"None\" # 'quadratic', 'entropic'    \n",
    "    hint_type = \"None\"\n",
    "    delay_param = 0\n",
    "    exp_name = \"None\" # Set experiment name, use \"None\" if not running an experiment\n",
    "    \n",
    "'''\n",
    "Adaptive hinting parameters\n",
    "'''\n",
    "hint_alg = 'rmplus' # 'ftl', ftrl', 'adahedgefo', 'adahedgesr', 'flip_flop', 'rm', 'rmplus'\n",
    "hint_reg = \"None\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "Read in ground truth and model predictions for task\n",
    "\"\"\"\n",
    "# Get location FIPS codes\n",
    "fips_codes = get_fips_codes() \n",
    "\n",
    "# Read ground truth dataframe\n",
    "printf(f'Loading {gt_id} ground truth')\n",
    "df_gt = get_ground_truth(gt_id, location, load_df=True)\n",
    "\n",
    "# Get target dates for which ground truth is avalible, inclusive\n",
    "first_date, last_date = get_data_range(gt_id, location=location)\n",
    "printf(f\"Getting target dates from {first_date} to {last_date}.\")\n",
    "\n",
    "# Get target dates between first and last date inclusive\n",
    "target_dates = get_target_dates(target_date_str, first_date, last_date)\n",
    "target_date_objs = pd.Series(target_dates)\n",
    "\n",
    "# Store delta between target date and forecast issuance date.\n",
    "# Accounts for the fact that predictions can be made up to Monday for\n",
    "# what will happen on EW Satuday.\n",
    "start_delta = timedelta(days=get_start_delta(horizon, gt_id))\n",
    "\n",
    "# Get model predicitons for the task; use load_df to use previously\n",
    "# compiled dataframe if avalible. Otherwise, generated fresh dataframe\n",
    "# from data source.\n",
    "printf(f'Loading model predictions for {gt_id}, {horizon}, {location}, q{quantile}')\n",
    "model_pred_df = get_model_predictions(gt_id, horizon, location=location, quantile=quantile, load_df=True)\n",
    "\n",
    "display(model_pred_df)\n",
    "# Get list of persistant models; models that have come online at some point\n",
    "# and made predictions for the entire period. \n",
    "persistant_models, all_models, all_models_dates = get_persistant_models(model_pred_df)\n",
    "expert_models = list(all_models)\n",
    "expert_models.sort()\n",
    "model_string = (',').join(expert_models)\n",
    "persistant_index = dict(zip(all_models, range(len(all_models))))\n",
    "printf(f\"Predictions for models loaded:\\n {expert_models}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "Visualize ground truth \n",
    "\"\"\"\n",
    "df_gt.plot()\n",
    "plt.xticks(rotation=90)\n",
    "plt.title(f'Ground truth {gt_id}')\n",
    "plt.show()\n",
    "\n",
    "\"\"\"\n",
    "Visualize avalible models\n",
    "\"\"\"\n",
    "plt.plot(list(all_models_dates.keys())[::-1], [len(x) for x in all_models_dates.values()][::-1])\n",
    "plt.xticks(rotation=90)\n",
    "plt.title('All models avaliable by date')\n",
    "plt.show()\n",
    "\n",
    "\"\"\"\n",
    "Visualize persistant models\n",
    "\"\"\"\n",
    "plt.plot(list(persistant_models.keys())[::-1], [len(x) for x in persistant_models.values()][::-1])\n",
    "plt.xticks(rotation=90)\n",
    "plt.title('Persistant models avaliable by date')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "Set up online learning parameterization\n",
    "\"\"\"\n",
    "# Record submodel name for the online expert model\n",
    "submodel_name = get_submodel_name(\n",
    "    expert_models=model_string, \n",
    "    reg=reg, \n",
    "    alg=alg, \n",
    "    hint = hint_type,\n",
    "    delay=delay_param,\n",
    "    training_dates=target_date_str,\n",
    "    exp_name=exp_name)\n",
    "\n",
    "printf(f\"Submodel name {submodel_name}\")\n",
    "\n",
    "if not isnotebook():\n",
    "    # TODO: need to set this up\n",
    "    # Save output to log file\n",
    "    logger = start_logger(model=model_name,submodel=submodel_name,gt_id=gt_id,\n",
    "                          horizon=horizon,target_dates=target_date_str)\n",
    "    # Store parameter values in log                                                                                                                        \n",
    "    params_names = ['gt_id', 'horizon', 'target_date_str',\n",
    "                    'model_string', 'alg',\n",
    "                    'reg', 'reset_quarters', 'hint_type',\n",
    "                    'delay_param', 'exp_name']\n",
    "    params_values = [eval(param) for param in params_names]\n",
    "    log_params(params_names, params_values)  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "Instantiate loss\n",
    "'''\n",
    "rodeo_loss = MAELoss()\n",
    "hint_loss = HintingLossTwoNorm()\n",
    "\n",
    "\n",
    "''' Duration '''\n",
    "duration = len(target_date_objs)\n",
    "active_experts = np.zeros((len(expert_models),), dtype=bool)\n",
    "''' \n",
    "Instantiate prototype online learner\n",
    "'''\n",
    "\n",
    "# Instantiate expert\n",
    "num_experts = delay_param + 1\n",
    "oe = get_expert(alg=alg, loss=rodeo_loss, T=duration//num_experts, \n",
    "                expert_list=expert_models, init_method=\"uniform\", reg=reg, active_experts=active_experts)  \n",
    "printf(f\"-initializing online_expert for with duration {duration//num_experts}\")   \n",
    "\n",
    "'''\n",
    "Instantiate hint generator\n",
    "'''\n",
    "if alg == \"rm\" or alg == \"rmplus\":\n",
    "    regret_hints = True # Provide pseudo-regret hints\n",
    "else:\n",
    "    regret_hints = False # Provide cummulative gradient hints\n",
    "\n",
    "# TODO: delay horizon \n",
    "# In order, list of 1 day hints, 12w hints, 34w hint, future hints, etc.\n",
    "horizon_hints = [[hint_type], \n",
    "                 [hint_type],\n",
    "                 [hint_type],\n",
    "                 [hint_type]]    \n",
    "    \n",
    "n_hints = [sum(len(x) for x in horizon_hints)]\n",
    "hint_models = [item + str(i) for i, sublist in enumerate(horizon_hints) for item in sublist]\n",
    "hint_partition = [i for i, sublist in enumerate(horizon_hints) for item in sublist]\n",
    "\n",
    "# Initialize \n",
    "printf(f\"-initializing joint hinter of type {hint_models}\")   \n",
    "hinter = JointHinter(gt_id, horizon_hints, oe, regret_hints)\n",
    "\n",
    "'''\n",
    "Instantiate prototype online hinter\n",
    "'''\n",
    "oh = get_expert(alg=hint_alg, loss=hint_loss, T=duration//num_experts, \n",
    "                expert_list=hint_models, init_method=\"uniform\", reg=hint_reg,\n",
    "                partition=hint_partition) \n",
    "\n",
    "printf(f\"-initializing online_expert for with duration {duration//num_experts}\")  \n",
    "\n",
    "\n",
    "\n",
    "# Store losses\n",
    "forecast = pd.Series(index=target_date_objs, dtype='float64')\n",
    "losses = pd.Series(index=target_date_objs, dtype='float64')\n",
    "regret_gt = pd.DataFrame(columns=expert_models, index=target_date_objs, dtype='float64')\n",
    "regret_gt.fillna(0, inplace=True) # Fill with zeros\n",
    "\n",
    "online_params = None\n",
    "online_hint_params = None\n",
    "hint_pred_df = None\n",
    "expert_pred_df = pd.DataFrame(index=target_date_objs, columns=expert_models)\n",
    "expert_pred_df = expert_pred_df.fillna(0)\n",
    "\n",
    "'''\n",
    "Initialize online experts\n",
    "'''\n",
    "ei = 0\n",
    "experts_dates = {}\n",
    "hinters_dates = {}\n",
    "experts_queue = [None]*(num_experts)\n",
    "hinters_queue = [None]*(num_experts)\n",
    "for e in range(num_experts):\n",
    "    experts_dates[e] = []    \n",
    "    hinters_dates[e] = []      \n",
    "    hinters_queue[e] = copy.deepcopy(oh)        \n",
    "    experts_queue[e] = copy.deepcopy(oe)    \n",
    "      \n",
    "'''\n",
    "Perform online prediction\n",
    "'''\n",
    "for target_date_obj in target_date_objs:\n",
    "    printf(f\"\\n\\n\\t----- Starting {target_date_obj}\") \n",
    "    \n",
    "    # Convert target date to string\n",
    "    date_str = datetime.strftime(target_date_obj, '%Y-%m-%d')  \n",
    "    \n",
    "    \"\"\"\n",
    "    Get the set of active, persistant models\n",
    "    \"\"\"\n",
    "    if date_str not in persistant_models:\n",
    "        printf(f'Skipping target. No persistant models avalible.')\n",
    "        continue\n",
    "        \n",
    "    active_models = persistant_models[date_str]\n",
    "    active_ind = [persistant_index[x] for x in active_models]\n",
    "    printf(f\"There are {len(active_models)} avalible models {active_models} at index {active_ind}\")\n",
    "        \n",
    "    tic()\n",
    "    # Get value of current prediction\n",
    "    pred_cur = model_pred_df.loc[(model_pred_df.index.get_level_values('target_end_date') == date_str)]\n",
    "    # Get active models\n",
    "    pred_cur = pred_cur[pred_cur.index.get_level_values(\"model\").isin(active_models)].droplevel([1,2])\n",
    "    expert_pred_df.loc[target_date_obj, active_models] = pred_cur.value\n",
    "    toc()\n",
    "            \n",
    "    '''\n",
    "    Get an avalible expert to make a prediction for target dates. \n",
    "    '''\n",
    "    cur_oe = experts_queue[ei]\n",
    "    cur_oh = hinters_queue[ei] \n",
    "    \n",
    "    # Update parameter logging\n",
    "    params = cur_oe.log_params()\n",
    "    hint_params = cur_oh.log_params()            \n",
    "    \n",
    "    # Update parameter set for dates in target range\n",
    "    if online_params is None:                                                \n",
    "         online_params = pd.DataFrame(params, index=[target_date_obj])        \n",
    "    else:                                                                    \n",
    "        online_params.loc[target_date_obj] = copy.copy(params)\n",
    "        \n",
    "    if online_hint_params is None:                                                \n",
    "         online_hint_params = pd.DataFrame(hint_params, index=[target_date_obj])        \n",
    "    else:                                                                    \n",
    "        online_hint_params.loc[target_date_obj] = copy.copy(hint_params)          \n",
    "    '''\n",
    "    Update model weights with previously avaliable ground truth; use current \n",
    "    prediction to provide optimistic hint, if necessary.\n",
    "    '''\n",
    "    pred = None # Initialize prediction\n",
    "    printf(f\"Making target prediction {target_date_obj} using expert {ei} with experience {cur_oe.t}.\")  \n",
    "    \n",
    "    # Add current target date to outstanding predictions\n",
    "    experts_dates[ei].append(target_date_obj)\n",
    "\n",
    "    last_data_date = target_date_obj - start_delta\n",
    "    printf(f\"--Last data date {last_data_date}\")\n",
    "\n",
    "    # Get expert prediction dates that are avalible for updates\n",
    "    update_dates = [x for x in experts_dates[ei] if x <= last_data_date]\n",
    "    if len(update_dates) > 1:\n",
    "        raise ValueError(f\"Warning: more than one date in the update queue {len(update_dates)}\")\n",
    "\n",
    "    for date in update_dates:\n",
    "        dstr = datetime.strftime(date, '%Y-%m-%d')  \n",
    "        expert_pred = expert_pred_df.loc[date]\n",
    "        hinter_pred = hint_pred_df.loc[(hint_pred_df.index.get_level_values('target_date') == date)]\n",
    "        \n",
    "        if df_gt.index.get_level_values(\"date\").isin([dstr]).any():   \n",
    "            printf(f\"Updating expert {ei} w/{cur_oe.t} experience with forecast on {target_date_obj}.\")\n",
    "            printf(f\"--Outstanding expert predictions: {len(experts_dates[ei])} for expert {ei}\")   \n",
    "            \n",
    "            d = experts_dates[ei].pop(0) # Remove prediction to be updated from outstanding predictions\n",
    "\n",
    "            # Check that that oustanding prediction is correct\n",
    "            if d != date: raise ValueError(f\"Bad date {d} != {date}\")\n",
    "            \n",
    "            ''' Set values of experts without predictions to zero'''\n",
    "            # Ground truth\n",
    "            gt_val = float(df_gt[df_gt.index.get_level_values(\"date\") == dstr]['gt'])\n",
    "            \n",
    "            ''' Get loss gradient '''      \n",
    "            grad = cur_oe.loss_gradient(\n",
    "                     X=expert_pred.to_numpy(copy=False), \n",
    "                     y=gt_val,\n",
    "                     w=online_params.loc[date][expert_models].to_numpy(copy=False))\n",
    "\n",
    "            ''' Update regret ground truth '''\n",
    "            r = cur_oe.loss_regret(g=grad, w=online_params.loc[date][expert_models].to_numpy(copy=False))\n",
    "            regret_gt.loc[date, expert_models] = r\n",
    "               \n",
    "\n",
    "            ''' Get hint value '''  \n",
    "            hinter.update_hint_data(g_fb=grad, y_fb=gt_val)  \n",
    "            \n",
    "            H = hinter.get_hint_matrix(\n",
    "                        X_all=expert_pred_df,\n",
    "                        y_all=df_gt,\n",
    "                        w_all=online_params[expert_models],\n",
    "                        last_data_date=last_data_date,\n",
    "                        os_preds=experts_dates[ei])\n",
    "\n",
    "            ''' Get hint weights '''\n",
    "            hint = cur_oh.update_and_predict(\n",
    "                         X_cur=H,\n",
    "                         X_fb=hint_pred_df.loc[date].to_numpy(copy=False).T, \n",
    "                         y_fb=regret_gt.loc[experts_dates[ei], :].to_numpy(copy=False).sum(axis=0),\n",
    "                         w_fb=online_hint_params.loc[date, hint_models].to_numpy(copy=False))\n",
    "            printf(f\"Hint: {hint}\")  \n",
    "            \n",
    "            ''' Get prediction for target date '''\n",
    "            pred = cur_oe.update_and_predict(\n",
    "                         X_cur=expert_pred_df.loc[target_date_obj].to_numpy(copy=False),\n",
    "                         active_ind=active_ind,\n",
    "                         hint=hint,\n",
    "                         X_fb=expert_pred.to_numpy(copy=False), \n",
    "                         y_fb=gt_val,\n",
    "                         w_fb=online_params.loc[date][expert_models].to_numpy(copy=False))\n",
    "\n",
    "            # Remove updated date; TODO may not need this\n",
    "            expert_pred_df.drop(date, inplace=True)    \n",
    "                \n",
    "    # If no data was avaliable for predict and update, make a prediction without feedback\n",
    "    if pred is None:\n",
    "        # Before the first feedback\n",
    "        H = hinter.get_hint_matrix(\n",
    "                        X_all=expert_pred_df,\n",
    "                        y_all=df_gt,\n",
    "                        w_all=online_params[expert_models],       \n",
    "                        last_data_date=last_data_date,\n",
    "                        os_preds=experts_dates[ei])\n",
    "        \n",
    "        hint = cur_oh.update_and_predict(X_cur=H)        \n",
    "        # printf(f\"Hint grad sum: {hint}\")\n",
    "        '''\n",
    "        Get prediction for target date without feedback\n",
    "        '''\n",
    "        pred = cur_oe.update_and_predict(\n",
    "                     X_cur=expert_pred_df.loc[target_date_obj].to_numpy(copy=False),\n",
    "                     active_ind=active_ind,            \n",
    "                     hint=hint)\n",
    "    '''\n",
    "    Update hinting historical parameters\n",
    "    '''\n",
    "    index = pd.MultiIndex.from_arrays(\n",
    "        [[target_date_obj]*len(hint_models), hint_models], \n",
    "        names=('target_date', 'hint'))\n",
    "    \n",
    "    if hint_pred_df is None:\n",
    "        hint_pred_df = pd.DataFrame(H.T, columns=expert_models, index=index)        \n",
    "    else:\n",
    "        df = pd.DataFrame(H.T, columns=expert_models, index=index)                \n",
    "        hint_pred_df = pd.merge(hint_pred_df, df, on=expert_models,\n",
    "                         left_index=True, right_index=True, how='outer')\n",
    "        \n",
    "    '''\n",
    "    Mark the current expert as busy until delay_delta days before gt is avalible\n",
    "    '''\n",
    "    # Add expert with key providing the next target date for which the expert can make predictions\n",
    "    ei = (ei+1) % num_experts\n",
    "    '''\n",
    "    Save forecasts and update metric logging\n",
    "    '''\n",
    "    params = cur_oe.log_params()\n",
    "    hint_params = cur_oh.log_params()    \n",
    "    printf(f\"-alg params:\\n{params}\\n\")\n",
    "    printf(f\"-hint params:\\n{hint_params}\\n\")        \n",
    "\n",
    "    # Update parameter set for dates in target range\n",
    "    if online_params is None:                                                \n",
    "         online_params = pd.DataFrame(params, index=[target_date_obj])        \n",
    "    else:                                                                    \n",
    "        online_params.loc[target_date_obj] = params.values()\n",
    "    if online_hint_params is None:                                                \n",
    "         online_hint_params = pd.DataFrame(hint_params, index=[target_date_obj])        \n",
    "    else:                                                                    \n",
    "        online_hint_params.loc[target_date_obj] = hint_params.values()        \n",
    "    \n",
    "    # Save forecast\n",
    "    forecast.loc[target_date_obj] = pred\n",
    "    \n",
    "    # Skip dates without forecast outputs\n",
    "    if not df_gt.index.get_level_values(\"date\").isin([date_str]).any():\n",
    "        printf(f\"warning: some features unavailable for target={target_date_obj}; skipping evalution.\")\n",
    "        printf(\"-mean loss: {}, running score: {}\".format(mean_loss, mean_loss_to_score(mean_loss)))        \n",
    "        printf(\"-loss: {}, score: {}\".format(loss, mean_loss_to_score(loss)))        \n",
    "    else: \n",
    "        # Evaluate and store error\n",
    "        gt_val = float(df_gt[df_gt.index.get_level_values(\"date\") == date_str]['gt'])\n",
    "        loss = cur_oe.loss(gt_val, pred)\n",
    "        losses.loc[target_date_obj] = loss\n",
    "        printf(\"-loss: {}\".format(loss))\n",
    "        mean_loss = losses.mean()\n",
    "        printf(\"-mean loss: {}\".format(mean_loss))\n",
    "        \n",
    "               \n",
    "# Save losses in standard format\n",
    "losses = losses.reset_index()\n",
    "losses.columns = ['target_date','loss']\n",
    "\n",
    "# Get output directory and create if it doesn't exist\n",
    "output_folder = get_task_metrics_dir(model=model_name, \n",
    "                                     submodel=submodel_name, \n",
    "                                     gt_id=gt_id, \n",
    "                                     horizon=horizon)\n",
    "make_directories(output_folder)\n",
    "metric_file_path = f'{output_folder}/loss-{gt_id}_{horizon}-{target_date_str}.h5'\n",
    "pandas2hdf(losses, metric_file_path)\n",
    "\n",
    "\n",
    "# Log online learning parameters to file\n",
    "logdir = get_task_forecast_dir(model=model_name, \n",
    "                               submodel=submodel_name,\n",
    "                               gt_id=gt_id, \n",
    "                               horizon=horizon)\n",
    "make_directories(logdir)\n",
    "file_path = f'{output_folder}/forecast-{gt_id}_{horizon}-{target_date_str}.h5'\n",
    "pandas2hdf(forecast, file_path)\n",
    "\n",
    "param_file_path = f'{logdir}/learning_params-{gt_id}_{horizon}-{target_date_str}.h5'\n",
    "pandas2hdf(online_params, param_file_path)\n",
    "\n",
    "hint_param_file_path = f'{logdir}/hint_params-{gt_id}_{horizon}-{target_date_str}.h5'\n",
    "pandas2hdf(online_hint_params, hint_param_file_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "Plot values\n",
    "\"\"\"\n",
    "gt_flat = df_gt.reset_index()\n",
    "plt.plot(forecast, label=f\"Ensemble forecast {gt_id}, {horizon}\")\n",
    "plt.plot(gt_flat['date'], gt_flat['gt'], label=f'Ground truth {gt_id}, {horizon}')\n",
    "plt.xticks(rotation=90)\n",
    "# plt.title(f'Ground truth {gt_id}')\n",
    "plt.legend()\n",
    "plt.show()\n",
    "\n",
    "\"\"\"\n",
    "Plot time-varying losses\n",
    "\"\"\"\n",
    "plt.plot(losses['target_date'], losses['loss'])\n",
    "plt.title('MAE loss')\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_pred_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
